<font color=LightCoral>**Problem:**</font>

<font color=LightBlue >**Solution:**</font>

<font color=Lime  >**Definition:**</font>

<font color=LightSalmon >**Remarks:**</font>

<font color=Aqua >**Lemma Theorem**</font>

<font color=Red >**Note:**</font>

<font color=DarkViolet >**Assumption:**</font>

<font color=HotPink >***Proof:***</font>

---

<center> <font size=8 ><b>3.Thompson Sampling</b></font></center> 

---



假设我们开了一家叫Surprise Me的饭馆

- 客人来了不用点餐，由算法从N道菜中选择一道菜推荐给客人
- 每道菜都有一定的失败概率：以1-p的概率不好吃，以p的概率做得好吃
- 算法的目标是让满意的客人越多越好。

[在之前的MAB中我们介绍了Upper Confidence Bound (UCB) 算法](https://zhuanlan.zhihu.com/p/32356077)来解决这个问题：

- 基于目前的数据，估计出每道菜被接受的概率$\tilde{p}$以及浮动范围$\Delta$
- 我们乐观的认为下一个应该推荐的菜应该是$\tilde{p}+\Delta$



## 1.UCB算法的缺点

但是UCB算法也有一定的缺点：

- 算法是确定性的，结果也是固定的，在模型更新前，推荐结果不会改变 ==这个不是很好理解==
- 无法融合先验知识，比如我们事先知道某些菜是比较好吃的
- [UCB的实际效果不一定好于我们接下来要介绍的方法](https://link.zhihu.com/?target=https%3A//papers.nips.cc/paper/4321-an-empirical-evaluation-of-thompson-sampling)

## 2.MAB里也有Frequentist vs Bayesian？！

回顾我们的问题：一道菜概率$p = \theta$做的好吃，以概率$p = (1-\theta)$做的不好吃

Frequentist 和 Bayesian学派对于参数$\theta$看法不一致

- Frequentist学派的看法

  - 认为$\theta$是一个客观存在的、固定的值，我们要做的就是通过多次试验来推测$\theta$的值，即$\tilde{\theta} = \sum_{i} reward_i /n$，当采集的样本无穷大时，$\tilde{\theta}$会趋近于真实的$\tilde{\theta}$
  - 现实中采样样本不可能是无穷大的，因此Frequentist还会计算出一个置信区间$\Delta$，也就有了UCB算法

- Bayesian (贝叶斯) 学派的看法

  - 虽然$\theta$是一个客观存在的、固定的值，但我们可以用一个概率分布来描述$\theta$的不确定性。随着样本的增加，这个概率分布在真实$\theta$附近的概率密度会越来越大


UCB是Frequentist学派的一个经典，本节我们介绍一个Bayesian方法 － Thompson Sampling

  

## Bernoulli MAB和Thompson Sampling

回顾我们的问题：一道菜以概率$p = \theta$做的好吃(reward=1)，以概率$p = (1-\theta)$做的不好吃(reward=0)，这是一个典型的Bernoulli (伯努利)分布
$$
p(reward|\theta) \sim Bernuolli(\theta)
$$
Bayesian学派会用概率分布来描述$\theta$不确定性
$$
p(\theta|reward) = \frac{p(reward|\theta)p(\theta)}{p(reward)} \propto p(reward|\theta) p(\theta) = Bernuolli(\theta)p(\theta)
$$
$p(\theta)$的选取直接决定了$Bernuolli(\theta)p(\theta)$的函数形式。在贝叶斯统计当中，$Bernuolli(\theta)$经常和$Beta(\alpha,\beta)$分布一起使用（称为共轭分布），$Bernuolli(\theta)Beta(\alpha,\beta)$得到一个新的$Beta$分布

- 如果$Bernoulli(\theta)$的结果为1，则会得到$Beta(\alpha+1,\beta)$
- 如果$Bernoulli(\theta)$的结果为0，则会得到$Beta(\alpha,\beta+1)$

有了$\theta$的不确定性，Bernoulli MAB的解决方案也就出来了 - Thompson Sampling:

- 步骤1: 用$p(\theta|reward)$刻画每道菜好吃的概率，得到$\{p(\theta_1|reward_1),...,p(\theta_N|reward_N)\}$
- 步骤2: 对每道菜$p(\theta_i|reward_i)$随机抽取一个样本$\theta_i$得到$\{\theta_1,..,\theta_N\}$
- 步骤3: 推荐$\theta_i$最大的那道菜，得到$reward_i$
- 步骤4: 更新$\theta_i$的分布：$p(\theta|reward) = Beta(\alpha',\beta') \propto Bernoulli(\theta)Beta(\alpha,\beta)$
  - 如果$reward_i =1$，那么有$Beta(\alpha+1,\beta)$
  - 如果$reward_i =0$，那么有$Beta(\alpha,\beta+1)$



